{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Make a summary about Chapter 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![summary](../Estimation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.7.3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Suppose $Y_1, Y_2, . . . , Y_n$ is a random sample from the exponential pdf, $$f_Y (y;λ) = λe^{−λy}, y > 0$$.\n",
    "1. Show that $\\hatλ_1 = Y_1$ is not consistent for λ.\n",
    "2. Show that $\\hatλ_2 = \\sum Y_i$ is not consistent for λ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\hat{\\lambda_1}$:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "        E(\\hat{\\lambda_1}) &= \\int_{0}^{\\infty} \\lambda y e^{-\\lambda y} \\\\\n",
    "        &= - \\int_{0}^{\\infty}  y d(e^{-\\lambda y}) \\\\\n",
    "        &= -[y e^{-\\lambda y}]^{\\infty}_{0} + \\int_{0}^{\\infty} e^{-\\lambda y} dy \\\\\n",
    "        &= [-\\frac{1}{\\lambda} e^{-\\lambda y}]^{\\infty}_0   \\\\\n",
    "        &= \\frac{1}{\\lambda}\n",
    "\\end{aligned} \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\lim_{n\\to \\infty} E(\\hat{\\lambda_1}) = \\frac{1}{\\lambda} \\neq \\lambda $$\n",
    "\n",
    "Thus,$\\hat{\\lambda_1}$ is not consistent with $\\lambda$\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. $\\hat{\\lambda_2}$:\n",
    "\n",
    "    By the CLT, when $n$ is sufficiently large, we have $\\bar{X} \\to^{d} N(E(X),\\frac{Var(X)}{n})$\n",
    "\n",
    "    For $\\hat{\\lambda_2}= \\sum Y_i $, we have $\\hat{\\lambda_2} = n\\bar{Y} \\to^{d} N(n\\cdot E(X),{n\\cdot Var(X)}) $\n",
    "\n",
    "    Thus, $\\lim_{n\\to \\infty} E(\\hat{\\lambda_2}) = \\frac{n}{\\lambda} \\neq \\lambda$, suggesting that $\\hat{\\lambda_2}$ is not consistent with $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 5.7.4\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ An estimator $\\hatθ$ is said to be squared-error consistent for θ if $$\\lim_{n→∞}E[(\\hatθ − θ)^2] = 0$$.\n",
    "1. Show that any squared-error consistent $\\hatθ$ is asymptotically unbiased (see Question 5.4.15).\n",
    "2. Show that any squared-error consistent $\\hatθ$ is consistent in the sense of Definition 5.7.1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Asymptotic Unbiasedness:\n",
    "\n",
    "\\begin{align*}\n",
    "        \\lim_{n\\to\\infty}E[\\hat{\\theta}^2 - 2\\hat{\\theta}\\times \\theta + \\theta^2] &= 0  \\\\\n",
    "        \\lim_{n\\to\\infty}E[\\hat{\\theta}^2] - 2E[\\hat{\\theta}]\\times \\theta + \\theta^2 &= 0 \\\\\n",
    "        \\lim_{n\\to\\infty} E[\\hat{\\theta}] &= \\theta\n",
    "\\end{align*}\n",
    "\n",
    "Thus, $\\hat{\\theta}$ is asymtotically unbiased.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Consistency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align*}\n",
    "        \\lim_{n\\to\\infty}E[(\\hatθ − θ)^2] &= 0 \\\\\n",
    "        \\lim_{n\\to\\infty} P[(\\hatθ − θ)^2\\leq \\epsilon] &\\geq 1-\\frac{E[(\\hatθ − θ)^2]}{\\epsilon} \\text{(By Markov's inequality)}\\\\\n",
    "        \\lim_{n\\to\\infty} P[(\\hatθ − θ)^2\\leq \\epsilon] &= 1    \\\\\n",
    "        \n",
    "\\end{align*}\n",
    "\n",
    "Thus, $\\hat{\\theta}$ is consistent with $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 6.2.5 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If $H_0: μ = μ_o$ is rejected in favor of $H_1: μ > μ_o$, will it necessarily be rejected in favor of $H_1: μ \\neq μ_o$? \n",
    "  + Assume that $α$ remains the same."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $H_0$ is rejuected at the significance level of $\\alpha$, $$ p-value = P(\\text{Reject }H_0|\\mu = \\mu_o) \\leq \\alpha $$\n",
    "\n",
    "When $H_1:μ > μ_o$ converts to $H_1: μ \\neq μ_o$, $ p-value = P(\\text{Reject }H_0|\\mu = \\mu_o)$ does not change.\n",
    "\n",
    "Thus, $H_0$ is necessarily rejuected at the significance level of $\\alpha$ in favour of $H_1:\\mu \\neq \\mu_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 6.2.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Suppose $H_0: μ = 120$ is tested against $H_1: μ \\neq 120$.\n",
    "+ If $σ = 10$ and $n = 16$, what P-value is associated with the sample mean $y = 122.3$? \n",
    "  + Under what circumstances would $H_0$ be rejected?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the test statistic: $$t = \\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}} \\to^{H_0} N(0,1)$$\n",
    "\n",
    "Compute the z-socre of the test statistic: $$ z = \\int_{-\\infty}^{t} \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}dx = 0.821213620385628 $$\n",
    "\n",
    "Compute the p-value:$$p-value = P(|T|\\geq |t| = 0.92|\\mu = 120) = 2\\times(1-z) = 0.3575727592287441$$\n",
    "\n",
    "Thus, $H_0$ can be rejected with the significance level of $\\alpha \\leq 0.3575727592287441 $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第6题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Summarize the procedure of Hypothesis Testing. \n",
    "+ Use your know words to explain the basic idea/principle of hypothesis testing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determines the null hypothesis $H_0$ and the alternative hypothesis $H_1$\n",
    "2. Choose a proper test statistic whose distribution or asymptotic distribution is known and contains parameters of interest.$$T(X^n) \\sim WhateverDistribution(...)$$\n",
    "3. Compute the critical value and the critical region based on the significance level $\\alpha = P(T\\text{ is more extrme than }t(x^n)_{obs}|H_0\\text{ is True})$\n",
    "   + Or compute the p-value \n",
    "4. By comparing the significance level and the p-value, decide whether to reject the null hypothesis $H_0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第7题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Prove the Cram´er-Rao Lower bound of Theorem 5.5.1 in Page 320.\n",
    "  + (Check the slides. Don’t just copy the slides and you can write the proof using your logic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Proof:\n",
    "\n",
    "\\begin{aligned}\n",
    "          \\text{By the Cauchy-Schwarz inequality:} \n",
    "          Cov^2[\\hat{\\theta},\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}] &\\leq Var(\\hat{\\theta})\\times Var[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "          Var(\\hat{\\theta}) &\\geq \\frac{Cov^2[\\hat{\\theta},\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]}{Var[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]}   \\\\\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compute $Cov^2[\\hat{\\theta},\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]$:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "        &Cov^2[\\hat{\\theta},\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}] \\\\\n",
    "          &= E\\{ \\hat{\\theta}\\times \\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta} \\} -E(\\hat{\\theta}) E[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "          &= \\int \\hat{\\theta} \\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta} f_{Y^n}(y,\\theta) dy  \\\\\n",
    "          &= \\int \\hat{\\theta} \\frac{\\partial f_{Y^n}(y,\\theta)}{\\partial \\theta} dy  \\\\\n",
    "          \\text{Exchange the order of differentiation and integration:}&= \\frac{\\partial [\\int \\frac{\\partial f_{Y^n}(y,\\theta)}{\\partial \\theta} dy]}{\\partial \\theta} \\\\\n",
    "          &= \\frac{\\partial E(\\hat{\\theta})}{\\partial \\theta} = \\frac{d E(\\hat{\\theta})}{d \\theta}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compute $Var[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]$:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "        &Var[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "        &= E[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]^2 - E^2[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "        &= E[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]^2 +0 \\\\\n",
    "        &= E[\\frac{\\partial \\ln \\prod_{i=1}^n f_{Y_i}(y,\\theta)}{\\partial \\theta}]^2  \\\\\n",
    "        &= E[\\frac{\\partial \\sum_{i=1}^n\\ln  f_{Y_i}(y,\\theta)}{\\partial \\theta}]^2 \\\\\n",
    "        &= \\sum_{i=j=1}^n E[\\frac{\\partial  \\ln  f_{Y_i}(y,\\theta)}{\\partial \\theta}]^2  + \\sum_{i\\neq j}^n E[\\frac{\\partial  \\ln  f_{Y_i}(y,\\theta)}{\\partial \\theta}\\times \\frac{\\partial f_{Y_j}(y,\\theta)}{\\partial \\theta}]\\\\\n",
    "        &= nE[\\frac{\\partial \\ln f_{Y}(y,\\theta)}{\\partial \\theta}]^2 + \\sum_{i\\neq j}^n E[\\frac{\\partial  \\ln  f_{Y_i}(y,\\theta)}{\\partial \\theta}] E[\\frac{\\partial f_{Y_j}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "        &= nE[\\frac{\\partial \\ln f_{Y}(y,\\theta)}{\\partial \\theta}]^2 + 0\\\\\n",
    "        &= n\\times I(\\theta)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ Where $\\frac{\\partial \\ln(f(y,\\theta))}{\\partial \\theta}$ is called **score function**\n",
    "  + Property：$E\\{ \\frac{\\partial \\ln(f(y,\\theta))}{\\partial \\theta} \\} =0$\n",
    "  + Proof:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "                &E[\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta}]  \\\\\n",
    "                &= \\int \\frac{1}{f_{Y^n}(y,\\theta)} \\frac{\\partial f_{Y^n}(y,\\theta)}{\\partial \\theta}f_{Y^n}(y,\\theta)dy  \\\\\n",
    "                &= \\int \\frac{\\partial f_{Y^n}(y,\\theta)}{\\partial \\theta} dy   \\\\\n",
    "                &= \\frac{\\partial (\\int f_{Y^n}(y,\\theta)dy)}{\\partial \\theta} \\text{(Exchange the order of differentiation and integration)}\\\\\n",
    "                &= \\frac{\\partial 1}{\\partial \\theta} = 0\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ $E[\\frac{\\partial \\ln(f_{Y}(Y,\\theta))}{\\partial \\theta}]^2 = -E[\\frac{\\partial^2 \\ln(f_{Y}(Y,\\theta))}{\\partial\\theta^2 }]$\n",
    "    + Proof:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "            \\int \\frac{\\partial \\ln(f(y,\\theta))}{\\partial \\theta}f(y,\\theta)dy&=0 \\text{ (property of score function)} \\\\\n",
    "              \\int \\frac{f(y,\\theta)}{f(y,\\theta)} \\frac{\\partial f(y,\\theta)}{\\partial \\theta}&=0 \\\\\n",
    "            \\text{Exchange the order of integration/differentiation：}   \\frac{\\partial [\\int f(y,\\theta)dy] }{\\partial \\theta }&=0 \\\\\n",
    "            \\text{Differentiating by }\\theta：\\space\\Rightarrow \\int (\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta})^2 f(y,\\theta)dy + \\int \\frac{\\partial^2 \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta^2} f(y,\\theta) dy  &=0  \\\\\n",
    "              \\int (\\frac{\\partial \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta})^2 f(y,\\theta)dy  &= -\\int \\frac{\\partial^2 \\ln f_{Y^n}(y,\\theta)}{\\partial \\theta^2} f(y,\\theta) dy\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第8题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Write a reading note on the asymptotical properties of MLE based on the material I sent to you (Lecture 3 of the MIT course: Statistics for Applications). \n",
    "+ You can try to write the proof of the asymptotical normality of MLE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the population parameter be $\\theta$ whose MLE is $\\hat{\\theta}$.\n",
    "\n",
    "Under regularity conditions, we have $$ l(\\hat{\\theta}) \\approx l(\\theta) + l'(\\theta)(\\hat{\\theta} - \\theta)  $$(using Taylor expansion), where $l(\\theta) = \\frac{\\partial[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta}$, standing for the score function.\n",
    "\n",
    "Given the property of the score function $l(\\hat{\\theta}) = 0$,we have $$ 0 \\approx l(\\theta) + l'(\\theta)(\\hat{\\theta} - \\theta)  $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    l(\\theta) + l'(\\theta)(\\hat{\\theta} - \\theta) &\\approx 0    \\\\\n",
    "    \\frac{\\partial[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta} + \\frac{\\partial^2[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta^2}(\\hat{\\theta} - \\theta) &\\approx 0   \\\\\n",
    "    (\\hat{\\theta} - \\theta) \\approx \\frac{l(\\theta)}{l'(\\theta)}&=\\frac{\\partial[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta}/\\frac{\\partial^2[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $l'(\\theta)$：\n",
    "\n",
    "\\begin{align*}\n",
    "    l'(\\theta) &= \\frac{\\partial^2[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta^2}    \\\\\n",
    "    &= \\frac1n\\sum_{i=1}^n\\frac{\\partial^2[\\ln (f_X(\\theta;x_i))]}{\\partial \\theta^2} \\text{(Exchange summation/differetiation order)}    \\\\\n",
    "    &= \\frac1n\\sum_{i=1}^n -[\\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta}]^2   \\\\\n",
    "    &\\approx E\\{ -[\\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta}]^2 \\} \\\\\n",
    "    &= I(\\theta) \\text{(Defination of Fisher infomation)}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive $l(\\theta)$:\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\sqrt{n}l(\\theta) &= \\sqrt{n}\\frac{\\partial[\\frac1n\\sum_{i=1}^n\\ln (f_X(\\theta;x_i))]}{\\partial \\theta} \\\\\n",
    "    &= \\sqrt{n}\\frac1n\\sum_{i=1}^n(\\frac{\\partial[\\ln (f_X(\\theta;x_i))]}{\\partial \\theta} - 0 )  \\\\\n",
    "    &= \\sqrt{n}\\frac1n\\sum_{i=1}^n(\\frac{\\partial[\\ln (f_X(\\theta;x_i))]}{\\partial \\theta} - E[\\frac{\\partial[\\ln (f_X(\\theta;x_i))]}{\\partial \\theta}] ) \\text{ (Using porperty of score function) } \\\\\n",
    "    &\\approx \\sqrt{n}\\times E\\{  \\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta} - E[\\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta}]  \\} \\\\\n",
    "    &\\to^{d} N(0,n\\times Var(\\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta}))  = N(0,n\\times E(\\frac{\\partial\\ln (f_X(\\theta;x_i))}{\\partial \\theta})^2)\\\\\n",
    "    &= N(0,n\\times I(\\theta))\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, $$\\sqrt{n}\\times(\\hat{\\theta} - \\theta) = \\frac{l(\\theta)}{l'(\\theta)} \\to^{d} N(0,1)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
